{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test arabic gpt2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alichoo/alich/blob/master/test_arabic_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNv-VDNxTwDN",
        "outputId": "064da096-bf7f-4377-d361-948fde89efc6"
      },
      "source": [
        "!pip install -qq transformers\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.1MB 11.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 43.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 38.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQIJscvTzIUF",
        "outputId": "fcac9c01-e815-4820-f912-b6982b438663"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9ugGCMTG_Ee",
        "outputId": "f840863b-fe5d-4b05-f55e-45aa0c2ff92b"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "from transformers import pipeline, set_seed\n",
        " \n",
        "file_or_filename='/content/drive/MyDrive/CorpusArabicWSD.xml'\n",
        "# Open original file\n",
        "et = ET.parse(file_or_filename)\n",
        "root =et.getroot()\n",
        "for item in root.findall('document'):\n",
        "    data=item.findall('paragraph')\n",
        "    \n",
        "    for index  in range(0,len(data)):\n",
        "         \n",
        "        \n",
        "        sent = data[index].findall('sentence')\n",
        "        \n",
        "        for indexx  in range(0,len(sent)):\n",
        "            words =sent[indexx].findall('word')\n",
        "            for indexxx in range(0,len(words)):\n",
        "                generator = pipeline('text-generation', model='gpt2',use_fast=True)\n",
        "                set_seed(42)\n",
        "                if hasattr(words[indexxx], 'wn30_key'):\n",
        "                    continue\n",
        "                if hasattr(words[indexxx], 'generated'):\n",
        "                    continue\n",
        "                valadded=generator(words[indexxx].attrib['surface_form'], max_length=4, num_return_sequences=3 )\n",
        "                print(valadded)\n",
        "                for indexo in range(0,len(valadded)):\n",
        "                    print(indexxx, indexo) \n",
        "                    nexcc= ET.SubElement(sent[indexx], 'word')\n",
        "                    nexcc.attrib['surface_form']=valadded[indexo] ['generated_text']\n",
        "                    nexcc.attrib['generated']='true'\n",
        "            if hasattr(sent[indexx], 'generated'):\n",
        "                continue\n",
        "\n",
        "et.write(file_or_filename, encoding=\"UTF-8\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'و+l!'}, {'generated_text': 'و+h+'}, {'generated_text': 'و+ | |'}]\n",
            "0 0\n",
            "0 1\n",
            "0 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 32, but ``max_length`` is set to 4.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'فولتون هيئة المحلفين في مقاطعة'}, {'generated_text': 'فولتون هيئة المحلفين في مقاطعة'}, {'generated_text': 'فولتون هيئة المحلفين في مقاطعة'}]\n",
            "1 0\n",
            "1 1\n",
            "1 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}